# üß± Prerequisites to Install and Run the Model

## 1Ô∏è‚É£ Install a Supported Python Version

Make sure you have a Python version compatible with **Transformers**, **PyTorch**, and **Accelerate**.  
Recommended version: **Python 3.13.7** ‚Üí [Download here](https://www.python.org/downloads/release/python-3137/)

### üß© Compatibility Summary

| Library | Minimum Version | Python 3.13 Support | Notes |
|----------|-----------------|--------------------|--------|
| **PyTorch** | `torch >= 2.5.0` | ‚úÖ Yes | Official wheels for Python 3.13 available since 2.5.0 ‚Äî use CPU or CUDA builds from [pytorch.org/whl](https://download.pytorch.org/whl/) |
| **Transformers** | `transformers >= 4.46.0` | ‚úÖ Yes | Fully compatible with Python 3.13 and PyTorch 2.5 |
| **Accelerate** | `accelerate >= 1.0.0` | ‚úÖ Yes | Optional helper for performance and multi-device inference |

---

## 2Ô∏è‚É£ Add Python to Environment Variables (Windows)

If Python isn‚Äôt recognized in PowerShell, add it to your environment variables:

```powershell
$pythonPath = "$env:LOCALAPPDATA\Programs\Python\Python313"
[System.Environment]::SetEnvironmentVariable("Path", $env:Path + ";$pythonPath;$pythonPath\Scripts", "User")
```

Then close and reopen PowerShell, and verify:

```powershell
python -V
pip --version
```

---

## 3Ô∏è‚É£ Upgrade `pip`

Ensure you have the latest package manager version:

```powershell
python -m pip install --upgrade pip
```

---

## 4Ô∏è‚É£ Install Required Libraries

Install the core dependencies:

```powershell
python -m pip install "torch>=2.5" "transformers>=4.46" accelerate
```

This installs:
- **PyTorch** ‚Üí deep learning engine  
- **Transformers** ‚Üí Hugging Face model API  
- **Accelerate** ‚Üí optional performance/device manager  

> üí° **GPU support:**  
> For NVIDIA GPUs, install the CUDA version of PyTorch:
> ```powershell
> python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
> ```

---

## 5Ô∏è‚É£ Clone the Model Repository

Download the ONNX-ready DeBERTa model directly from Hugging Face:

```powershell
git clone https://huggingface.co/protectai/deberta-v3-base-injection-onnx.git
```

This will create a local folder containing:
```
deberta-v3-base-injection-onnx/
 ‚îú‚îÄ model.onnx
 ‚îú‚îÄ config.json
 ‚îú‚îÄ tokenizer.json
 ‚îú‚îÄ vocab.json
 ‚îî‚îÄ merges.txt
```

---

## 6Ô∏è‚É£ Configure Environment Variables (ONNX Model Support)

Set the following environment variables in **PowerShell** to enable ONNX integration:

```powershell
setx ANDY_GUARD_PI_ONNX_PATH "C:\dev\Samples\onnx-deberta-v3-base\model.onnx"
setx ANDY_GUARD_DEBERTA_SPM_PATH "C:\dev\Samples\onnx-deberta-v3-base"
setx ANDY_GUARD_DEBERTA_CLS_ID 0
setx ANDY_GUARD_DEBERTA_SEP_ID 2
setx ANDY_GUARD_DEBERTA_PAD_ID 1
setx ANDY_GUARD_DEBERTA_MASK_ID 3
setx ANDY_GUARD_DEBERTA_UNK_ID 100
```

> ‚ö†Ô∏è After setting variables, **close and reopen** your terminal for the changes to take effect.

---

## 7Ô∏è‚É£ Run the API

Start the .NET API locally:

```powershell
dotnet run --project .\src\Andy.Guard.Api\Andy.Guard.Api.csproj --urls http://localhost:5000
```

You should see output similar to:

```
Now listening on: http://localhost:5000
Application started. Press Ctrl+C to shut down.
```

‚úÖ The API is now running and connected to your local ONNX-based DeBERTa model.
